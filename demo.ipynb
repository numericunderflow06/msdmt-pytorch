{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "seed_value = 2021\n",
    "lr = 0.0001\n",
    "epochs = 500\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "timestep = 10\n",
    "maxlen = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MSDMT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 timestep=10,\n",
    "                 portrait_dim=32,\n",
    "                 behavior_num=100 + 1,\n",
    "                 behavior_emb_dim=16,\n",
    "                 behavior_maxlen=64,\n",
    "                 behavior_dim=32,\n",
    "                 network_dim=32,\n",
    "                 dropout=0.5):\n",
    "        super(MSDMT, self).__init__()\n",
    "\n",
    "        self.timestep = timestep\n",
    "        self.dropout = dropout\n",
    "        self.portrait_dim = portrait_dim\n",
    "        self.behavior_num = behavior_num\n",
    "        self.behavior_emb_dim = behavior_emb_dim\n",
    "        self.behavior_maxlen = behavior_maxlen\n",
    "        self.behavior_dim = behavior_dim\n",
    "        self.network_dim = network_dim\n",
    "\n",
    "        # portrait network\n",
    "        self.portrait_lstm = nn.LSTM(input_size=self.portrait_dim, hidden_size=self.portrait_dim, batch_first=True)\n",
    "        self.portrait_norm = nn.LayerNorm(self.portrait_dim)\n",
    "        self.portrait_dense = nn.Linear(self.portrait_dim, self.portrait_dim, bias=False)\n",
    "\n",
    "        # behavior network\n",
    "        self.behavior_embedding = nn.Embedding(num_embeddings=self.behavior_num, embedding_dim=self.behavior_emb_dim, padding_idx=0)\n",
    "        self.behavior_conv1d = nn.Conv1d(in_channels=self.behavior_emb_dim, out_channels=self.behavior_dim, kernel_size=3, padding=1)\n",
    "        self.behavior_lstm = nn.LSTM(input_size=self.behavior_dim, hidden_size=self.behavior_dim, batch_first=True)\n",
    "        self.behavior_norm = nn.LayerNorm(self.behavior_dim)\n",
    "        self.behavior_dense = nn.Linear(self.behavior_dim, self.behavior_dim, bias=False)\n",
    "\n",
    "        # graph network\n",
    "        self.gcn_conv = GCNConv(in_channels=self.portrait_dim + self.behavior_dim, out_channels=self.network_dim)\n",
    "        self.gcn_dropout = nn.Dropout(p=self.dropout)\n",
    "        self.network_dense = nn.Linear(self.network_dim, self.network_dim)\n",
    "\n",
    "        # output layers\n",
    "        self.output1 = nn.Linear(self.network_dim, 1)\n",
    "        self.output2 = nn.Linear(self.network_dim, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        U, B, A = inputs  # U: user features, B: behavior sequence, A: adjacency matrix\n",
    "\n",
    "        # portrait network\n",
    "        H, _ = self.portrait_lstm(U)\n",
    "        H = H[:, -1, :]  # last time step\n",
    "        H = self.portrait_norm(H)\n",
    "        H = F.relu(self.portrait_dense(H))\n",
    "\n",
    "        # behavior network\n",
    "        B_emb = self.behavior_embedding(B)  # shape: (batch, behavior_maxlen, behavior_emb_dim)\n",
    "        B_emb = B_emb.permute(0, 2, 1)  # switch to (batch, channels, time)\n",
    "        B_conv = F.relu(self.behavior_conv1d(B_emb))  # shape: (batch, behavior_dim, behavior_maxlen)\n",
    "        B_pooled = torch.mean(B_conv, dim=2)  # global average pooling (batch, behavior_dim)\n",
    "        B_pooled = B_pooled.unsqueeze(1).repeat(1, self.timestep, 1)  # shape: (batch, timestep, behavior_dim)\n",
    "        O, _ = self.behavior_lstm(B_pooled)  # LSTM\n",
    "        O = O[:, -1, :]  # last time step\n",
    "        O = self.behavior_norm(O)\n",
    "        O = F.relu(self.behavior_dense(O))\n",
    "\n",
    "        # concatenate portrait and behavior features\n",
    "        X = torch.cat([H, O], dim=-1)\n",
    "\n",
    "        # graph network\n",
    "        X_dense, mask = to_dense_batch(X, batch=A)  # convert sparse graph to dense batch\n",
    "        V = F.relu(self.gcn_conv(X_dense, A))\n",
    "        V = self.gcn_dropout(V)\n",
    "        V = F.relu(self.network_dense(V))\n",
    "\n",
    "        # outputs\n",
    "        output1 = torch.sigmoid(self.output1(V))\n",
    "        output2 = self.output2(V)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "torch.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "def data_process(timestep=10, maxlen=64):\n",
    "    df_U = pd.read_csv('../data/sample_data_player_portrait.csv')\n",
    "    df_B = pd.read_csv('../data/sample_data_behavior_sequence.csv')\n",
    "    df_G = pd.read_csv('../data/sample_data_social_network.csv')\n",
    "    df_Y = pd.read_csv('../data/sample_data_label.csv')\n",
    "\n",
    "    # user features\n",
    "    U = df_U.drop(['uid', 'ds'], axis=1).values\n",
    "    U = U.reshape(-1, timestep, U.shape[-1])\n",
    "    U = torch.tensor(U, dtype=torch.float32)\n",
    "\n",
    "    # behavior sequences\n",
    "    B = df_B['seq'].apply(lambda x: x.split(',') if pd.notna(x) else []).values\n",
    "    B = torch.tensor(\n",
    "        nn.utils.rnn.pad_sequence(\n",
    "            [torch.tensor(list(map(int, seq)), dtype=torch.long) for seq in B],\n",
    "            batch_first=True,\n",
    "            padding_value=0\n",
    "        ),\n",
    "        dtype=torch.long\n",
    "    ).reshape(-1, timestep, maxlen)\n",
    "\n",
    "    # social network graph\n",
    "    G = nx.from_pandas_edgelist(df=df_G, source='src_uid', target='dst_uid', edge_attr=['weight'])\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    edge_index, edge_weight = from_scipy_sparse_matrix(A)\n",
    "\n",
    "    # labels\n",
    "    y1 = torch.tensor(df_Y['churn_label'].values, dtype=torch.float32).unsqueeze(-1)\n",
    "    y2 = torch.tensor(np.log(df_Y['payment_label'].values + 1), dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "    print('U:', U.shape)\n",
    "    print('B:', B.shape)\n",
    "    print('G:', A.shape)\n",
    "    print('y1:', y1.shape, 'y2:', y2.shape)\n",
    "\n",
    "    return U, B, edge_index, edge_weight, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "U, B, edge_index, edge_weight, y1, y2 = data_process(timestep=timestep, maxlen=maxlen)\n",
    "\n",
    "# dataset preparation\n",
    "N = U.shape[0]\n",
    "\n",
    "dataset = Data(x=torch.cat((U, B), dim=-1), edge_index=edge_index, edge_attr=edge_weight, y1=y1, y2=y2)\n",
    "data_loader = DataLoader([dataset], batch_size=N)\n",
    "\n",
    "# model and training\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed_value)\n",
    "\n",
    "for train_index, test_index in kfold.split(U.numpy(), y1.numpy().ravel()):\n",
    "\n",
    "    train_index, val_index = train_test_split(train_index, test_size=0.1, random_state=seed_value)\n",
    "\n",
    "    mask_train = torch.zeros(N, dtype=torch.bool)\n",
    "    mask_val = torch.zeros(N, dtype=torch.bool)\n",
    "    mask_test = torch.zeros(N, dtype=torch.bool)\n",
    "    mask_train[train_index] = True\n",
    "    mask_val[val_index] = True\n",
    "    mask_test[test_index] = True\n",
    "\n",
    "    model = MSDMT(timestep=timestep, behavior_maxlen=maxlen).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion1 = nn.BCEWithLogitsLoss()\n",
    "    criterion2 = nn.MSELoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output1, output2 = model([U.to(device), B.to(device), edge_index.to(device)])\n",
    "        loss1 = criterion1(output1[mask_train], y1[mask_train].to(device))\n",
    "        loss2 = criterion2(output2[mask_train], y2[mask_train].to(device))\n",
    "        loss = alpha * loss1 + beta * loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_output1, val_output2 = model([U.to(device), B.to(device), edge_index.to(device)])\n",
    "            val_loss1 = criterion1(val_output1[mask_val], y1[mask_val].to(device))\n",
    "            val_loss2 = criterion2(val_output2[mask_val], y2[mask_val].to(device))\n",
    "            val_loss = alpha * val_loss1 + beta * val_loss2\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n",
    "\n",
    "        # early stopping\n",
    "        if val_loss.item() < best_loss:\n",
    "            best_loss = val_loss.item()\n",
    "            wait = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    # load the best model for evaluation\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_output1, test_output2 = model([U.to(device), B.to(device), edge_index.to(device)])\n",
    "        test_loss1 = criterion1(test_output1[mask_test], y1[mask_test].to(device))\n",
    "        test_loss2 = criterion2(test_output2[mask_test], y2[mask_test].to(device))\n",
    "        print(f\"Test Loss: {alpha * test_loss1 + beta * test_loss2}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
